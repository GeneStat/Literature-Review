# Literature Review

This repository is licensed under [CC-BY-SA-4.0](LICENSE).

## Motivation

We started this repository to keep tracking related cutting-edge papers to find out the topic(s) and scientific questions to work on.

There are too many things worth investigating, nearly everywhere and anytime. We need to keep our curiosity and keep thinking about why and how to answer the why. Every question could be a good question, and there is no stupid question. What affects our decision is only about the strategies or methods for answering the questions.

Therefore, for our (virtual) team, the best question should be like this:

1. We like the field, and we believe in the value of answering the question.
2. We can get the data (public data, or new data we could generate by ourselves) that are required to answer the question.
3. The research procedure could be done by using our skills or experience (programming and statistics, so far).

## Paper List

Here goes a continuous updating paper list. We select at least ten papers to study every month. Unless it is crucial and necessary, only open access papers are selected and added to this list. Suggestion reasons and related comments are provided following each paper.

### December 2021

1. Abdelkader, W. *et al*. A Deep Learning Approach to Refine the Identification of High-Quality Clinical Research Articles From the Biomedical Literature: Protocol for Algorithm Development and Validation. **JMIR Res. Protoc**. 10, e29398 (2021). doi: [10.2196/29398](https://doi.org/10.2196/29398)

    This paper is added for Linlin's personal interest. There are so many new papers published every day. Sooner or later, we need AI to help us to select papers, or even read and understand the papers.

2. Beck, T. *et al*. Auto-CORPus: A Natural Language Processing Tool for Standardising and Reusing Biomedical Literature. bioRxiv 2021.01.08.425887 (2021) doi: [10.1101/2021.01.08.425887](https://doi.org/10.1101/2021.01.08.425887)

    This paper is also about NLP technology application on biomedical papers.

### November 2021

1. Masum, H. *et al*. Ten Simple Rules for Cultivating Open Science and Collaborative R&D. **PLoS Comput. Biol**. 9, 7–10 (2013). doi: [10.1371/journal.pcbi.1003244](https://doi.org/10.1371/journal.pcbi.1003244)

    Since our goal is to do scientific research **openly and transparently**, this paper should be a proper kick-off for this journey.

2. Rollin, G. *et al*. Wikipedia network analysis of cancer interactions and world influence. **PLoS One**. 14, e0222508 (2019). doi: [10.1371/journal.pone.0222508](https://doi.org/10.1371/journal.pone.0222508)

    Wikipedia provides an easy-to-access and large data source for us to know a new field quickly and mining for knowledge. This paper is an example of how to launch an analysis of Wikipedia data.

3. Pantziarka, P. *et al*. An Open Access Database of Licensed Cancer Drugs. **Front. Pharmacol**. 0, 236 (2021). doi: [10.3389/fphar.2021.627574](https://doi.org/10.3389/fphar.2021.627574)

    For public data mining, we usually generate an open-access database as the final product. The database could elevate other investigators' research.

4. Kampers, L. F. C. *et al*. From Innovation to Application: Bridging the Valley of Death in Industrial Biotechnology. **Trends Biotechnol**. 39, 1240–1242 (2021). doi: [10.1016/j.tibtech.2021.04.010](https://doi.org/10.1016/j.tibtech.2021.04.010)

    Although this is not even a research article paper, I added it here because I think it is crucial for us, a loosely connected virtual team. We want to do something innovative as well as in an open way. Sooner or later, financial supporting will be a critical problem, which could affect some of our decisions. So, keep caution and keep thinking about what value we could create and transfer, and then we should go further.

5. Kleanthous, S. *et al*. Perception of fairness in algorithmic decisions: Future developers’ perspective. **Patterns**. 0, 100380 (2021). doi: [10.1016/j.patter.2021.100380](https://doi.org/10.1016/j.patter.2021.100380)

    In this beginning month of our literature review journey, I tend to add some papers which may be helpful for us to build up our principles and core values. This research article is such an interesting example of judging algorithms in a scientific research way. Keeping being good but not evil is not an easy thing.

6. Paullada, A. *et al*. Data and its (dis)contents: A survey of dataset development and use in machine learning research. **Patterns**. 2, 100336 (2021). doi: [10.1016/j.patter.2021.100336](https://doi.org/10.1016/j.patter.2021.100336)

    Collecting and tidying up data is the first thing to do before we try statistical methods. This review provides information about dataset development and applications.

7. The Cancer Genome Atlas Research Network *et al*. The Cancer Genome Atlas Pan-Cancer analysis project. **Nature Genetics**. 45, 1113-1120 (2013). doi: [10.1038/ng.2764](https://doi.org/10.1038/ng.2764)

    Since we are all interested in tumor-related research, TCGA, the largest public tumor data source is worth learning carefully. This paper is one of the earliest official papers about TCGA.

8. Ozhan, A. *et al*. SmulTCan: A Shiny application for multivariable survival analysis of TCGA data with gene sets. **Comput. Biol. Med**. 137, 104793 (2021). doi: [10.1016/j.compbiomed.2021.104793](https://doi.org/10.1016/j.compbiomed.2021.104793)

    This is a typical example of software development based on TCGA data.

9. Jia, D. *et al*. LINC02678 as a Novel Prognostic Marker Promotes Aggressive Non-small-cell Lung Cancer. **Front Cell Dev Biol**. 9, 686975 (2021). doi: [10.3389/fcell.2021.686975](https://doi.org/10.3389/fcell.2021.686975)

    This is a typical example of scientific research (biomarker discovery) project based on TCGA and GEO (Gene Expression Omnibus) data.

10. Fuhrman J. *et al*. A review of explainable and interpretable AI with applications in COVID-19 imaging. **Med Phys**. 2021 Nov 18. Online ahead of print. doi: [10.1002/mp.15359](https://doi.org/10.1002/mp.15359)

    We mentioned image processing for diagnosis. This review paper could provide some related knowledge.

11. Lee, C. M. *et al*. UCSC Genome Browser enters 20th year. **Nucleic Acids Res**. 48, D756–D761 (2020). doi: [10.1038/ng.2764](https://doi.org/10.1038/ng.2764)

    This is a long-term (20 years) software project, and it is one of the currently the most widely used websites. It integrates multi-omics data (annotations) in the order of genomic coordinates and provides many useful command-line tools. This is not the original paper of the software (UCSC genome browser), but an introduction paper after this long time.

12. Song, L. *et al*. CINdex: A Bioconductor Package for Analysis of Chromosome Instability in DNA Copy Number Data. **Cancer Inform**. 16, (2017). doi: [10.1177/1176935117746637](https://doi.org/10.1177/1176935117746637)

    This paper is about a R package, which provide an algorithm of calculating indicator to measure chromosome instability, which may be useful for tumor research and diagnosis.

14. Staedtke, V. *et al*. Actionable molecular biomarkers in primary brain tumors. **Trends in cancer** 2, 338–349 (2016). doi: [10.1016/j.trecan.2016.06.003](https://doi.org/10.1016/j.trecan.2016.06.003)

    This is a review paper, which introduces biomarkers (including genomic features such as chromosome instability) in brain tumor. This paper and above one are both provided in precisionFDA challenge.
